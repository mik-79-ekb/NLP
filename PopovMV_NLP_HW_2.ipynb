{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUotKHRULVPD"
      },
      "source": [
        "## Введение в обработку естественного языка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ba5Z02VLVPK"
      },
      "source": [
        "Домашнее задание №2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Урок 2. Создание признакового пространства"
      ],
      "metadata": {
        "id": "o4uu5xP0PcLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Формат именования файла домашней работы: FIO_NLP_HW_N.ipynb, где N - номер домашнего задания*\n",
        "\n",
        "**"
      ],
      "metadata": {
        "id": "p1MLiT1GPcOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1.\n",
        "Задание: обучите три классификатора:\n",
        "- на токенах с высокой частотой\n",
        "- на токенах со средней частотой\n",
        "- на токенах с низкой частотой\n",
        "\n",
        "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
        "\n",
        "Задание 2.  \n",
        "- найти фичи с наибольшей значимостью, и вывести их\n",
        "\n",
        "Задание 3.\n",
        "- сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
        "- подобрать оптимальный размер для hashing векторайзера\n",
        "- убедиться что для сетки нет переобучения"
      ],
      "metadata": {
        "id": "qLNtwEpLPcQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Установка и импорт необходимых библиотек**"
      ],
      "metadata": {
        "id": "Kef9NuDnPcUn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J5YiZNCPLVPe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0GieJSMU-O"
      },
      "source": [
        "### Задание 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка данных"
      ],
      "metadata": {
        "id": "eyJFOkJlRC5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZwb5ZU1RDcV",
        "outputId": "215d59c6-12a4-403e-e8a6-628007d45874"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 18:13:41--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
            "--2023-04-04 18:13:42--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucaf52935ba0612ad69d927e5e41.dl.dropboxusercontent.com/cd/0/inline/B5hiy-aBc-87dJx6sYwe0I-iNAAJ5GQd3Mvfe3hr4TognW67MvokFZjY-3ugILl5x7hdEbCkRhwhD02IWt2_i62Y93iUWE6TF68Ge1NR5hLQZEwUrN_JgbDc2iZl2m4SFTUKRdoYnbab-e4pYdJ74v_qmcnTDEu9GWmqe4RAWofRNA/file# [following]\n",
            "--2023-04-04 18:13:42--  https://ucaf52935ba0612ad69d927e5e41.dl.dropboxusercontent.com/cd/0/inline/B5hiy-aBc-87dJx6sYwe0I-iNAAJ5GQd3Mvfe3hr4TognW67MvokFZjY-3ugILl5x7hdEbCkRhwhD02IWt2_i62Y93iUWE6TF68Ge1NR5hLQZEwUrN_JgbDc2iZl2m4SFTUKRdoYnbab-e4pYdJ74v_qmcnTDEu9GWmqe4RAWofRNA/file\n",
            "Resolving ucaf52935ba0612ad69d927e5e41.dl.dropboxusercontent.com (ucaf52935ba0612ad69d927e5e41.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to ucaf52935ba0612ad69d927e5e41.dl.dropboxusercontent.com (ucaf52935ba0612ad69d927e5e41.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26233379 (25M) [text/plain]\n",
            "Saving to: ‘positive.csv’\n",
            "\n",
            "positive.csv        100%[===================>]  25.02M  14.7MB/s    in 1.7s    \n",
            "\n",
            "2023-04-04 18:13:45 (14.7 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
            "\n",
            "--2023-04-04 18:13:45--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
            "--2023-04-04 18:13:45--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca57e76f4a36fe11b7113ad74ae.dl.dropboxusercontent.com/cd/0/inline/B5iG7fpvr332xfs8vEk_UXFQbR08ttgBCmRei-ahLJzTaWLJzUwbQaWiiC55cxl-rDMcvNPJfBwBUNmtDW_q1-yaX519bixS_5lIk_gxbTUwe85fdBpl48gvja7F4pUAfTst8Rp2_4oLTCtL_-puDmq3Vx3-NZXlH0cS_Qg4mgzlUg/file# [following]\n",
            "--2023-04-04 18:13:46--  https://uca57e76f4a36fe11b7113ad74ae.dl.dropboxusercontent.com/cd/0/inline/B5iG7fpvr332xfs8vEk_UXFQbR08ttgBCmRei-ahLJzTaWLJzUwbQaWiiC55cxl-rDMcvNPJfBwBUNmtDW_q1-yaX519bixS_5lIk_gxbTUwe85fdBpl48gvja7F4pUAfTst8Rp2_4oLTCtL_-puDmq3Vx3-NZXlH0cS_Qg4mgzlUg/file\n",
            "Resolving uca57e76f4a36fe11b7113ad74ae.dl.dropboxusercontent.com (uca57e76f4a36fe11b7113ad74ae.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uca57e76f4a36fe11b7113ad74ae.dl.dropboxusercontent.com (uca57e76f4a36fe11b7113ad74ae.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24450101 (23M) [text/plain]\n",
            "Saving to: ‘negative.csv’\n",
            "\n",
            "negative.csv        100%[===================>]  23.32M  14.9MB/s    in 1.6s    \n",
            "\n",
            "2023-04-04 18:13:48 (14.9 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QUQ6kAgPMqNn",
        "outputId": "2cd209f5-d464-4ecf-8d5e-6c8de78fb833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "my_stopwords = stopwords.words('russian')\n",
        "noise = stopwords.words('russian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZCDkyls1NKGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575fc027-362a-48e5-c3b6-8c4ab3a8e70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-67f5acc3628f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = positive.append(negative)\n"
          ]
        }
      ],
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive)\n",
        "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative)\n",
        "df = positive.append(negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qflvcWQTNKGg",
        "outputId": "68d4854a-a051-4363-a6e0-43f20c93df07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "0       @first_timee хоть я и школота, но поверь, у на...  positive\n",
              "1       Да, все-таки он немного похож на него. Но мой ...  positive\n",
              "2       RT @KatiaCheh: Ну ты идиотка) я испугалась за ...  positive\n",
              "3       RT @digger2912: \"Кто то в углу сидит и погибае...  positive\n",
              "4       @irina_dyshkant Вот что значит страшилка :D\\nН...  positive\n",
              "...                                                   ...       ...\n",
              "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
              "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
              "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
              "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
              "111922  Такси везет меня на работу. Раздумываю приплат...  negative\n",
              "\n",
              "[226834 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eca44680-7005-4c3f-ac68-207b7121fd1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111918</th>\n",
              "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111919</th>\n",
              "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111920</th>\n",
              "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111921</th>\n",
              "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111922</th>\n",
              "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>226834 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eca44680-7005-4c3f-ac68-207b7121fd1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eca44680-7005-4c3f-ac68-207b7121fd1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eca44680-7005-4c3f-ac68-207b7121fd1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D9m4M-aRNKGg"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "Ik1hnsKhRnm2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bfi_KIjDNKGh"
      },
      "outputs": [],
      "source": [
        "def get_tokens_importance(maxdf, mindf):\n",
        "    \n",
        "    tfidf_vect = TfidfVectorizer(max_df=maxdf, # не берем слова что выше трешхолда\n",
        "                                 min_df=mindf, # не берем что ниже трешхолда\n",
        "#                                  max_features=1000, \n",
        "#                                  stop_words=noise,\n",
        "                                 )\n",
        "    \n",
        "    bow = tfidf_vect.fit_transform(x_train)\n",
        "    clf = LogisticRegression(random_state=42)\n",
        "    clf.fit(bow, y_train)\n",
        "    \n",
        "    pred = clf.predict(tfidf_vect.transform(x_test))\n",
        "    print(f'max_df= {maxdf} min_df= {mindf}')\n",
        "    print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": true,
        "id": "9-40Ksp1NKGh",
        "outputId": "7f89de3a-d6f2-4037-dd15-9c168fc70ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 1 min_df= 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.53      0.66     47567\n",
            "    positive       0.22      0.68      0.33      9142\n",
            "\n",
            "    accuracy                           0.55     56709\n",
            "   macro avg       0.56      0.60      0.50     56709\n",
            "weighted avg       0.79      0.55      0.61     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Берем все токены - f1-score получается низкая\n",
        "get_tokens_importance(1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "id": "qctJA864NKGi",
        "outputId": "47156719-3830-43ad-8b0d-767752ffe003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 1.0 min_df= 0.285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.36      0.61      0.45     16424\n",
            "    positive       0.77      0.55      0.64     40285\n",
            "\n",
            "    accuracy                           0.57     56709\n",
            "   macro avg       0.56      0.58      0.55     56709\n",
            "weighted avg       0.65      0.57      0.59     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Берем токены часто встречающиеся\n",
        "get_tokens_importance(1.0, 0.285)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": false,
        "id": "FcdOXWXfNKGi",
        "outputId": "97d976d2-78fa-41ad-be64-65badad0d3f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 0.7 min_df= 0.15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.35      0.61      0.44     16184\n",
            "    positive       0.78      0.55      0.64     40525\n",
            "\n",
            "    accuracy                           0.57     56709\n",
            "   macro avg       0.56      0.58      0.54     56709\n",
            "weighted avg       0.66      0.57      0.59     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Берем токены средне встречающиеся\n",
        "get_tokens_importance(0.7, 0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": false,
        "id": "EkW3pEK4NKGj",
        "outputId": "9f185d91-d226-463b-8cdb-c0ddf8bc3628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 0.3 min_df= 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.74      0.77      0.75     26994\n",
            "    positive       0.78      0.75      0.77     29715\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Берем токены низкочастотные\n",
        "get_tokens_importance(0.3, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV9vfhKZNKGj"
      },
      "source": [
        "Основываясь на результатах метрик можно выжвинуть гипотезу о том, что низкочастотные токены наиболее важны для классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AGvcaylNKGm"
      },
      "source": [
        "### Задание 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gUvutMNqNKGm"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGWBOoqIWQEY",
        "outputId": "a41d1284-ec04-4240-b33c-2b215f84e4f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kOWh3LrbNKGn",
        "outputId": "b1d55832-b884-4739-934d-1dcb9c39f8fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4027088\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@', 'first_timee', 'хоть', 'я', 'и', 'школота', ',', 'но', 'поверь', ',']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
        "corpus = [token for tweet in df.text for token in word_tokenize(tweet)]\n",
        "print(len(corpus))\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f4yL5lBbNKGn",
        "outputId": "633f7661-219e-4cdb-e7f6-9fb17bd4f162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('(', 212404),\n",
              " (')', 194005),\n",
              " (',', 188295),\n",
              " (':', 177675),\n",
              " ('@', 149978),\n",
              " ('не', 69472),\n",
              " ('!', 66923),\n",
              " ('.', 57623),\n",
              " ('и', 55166),\n",
              " ('в', 52902)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vtAyItvLVSb"
      },
      "source": [
        "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uqH07o-7LVSc",
        "outputId": "baa08b6a-9ea8-4a16-d354-f03860c36bc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.51      0.64     48330\n",
            "    positive       0.17      0.58      0.26      8379\n",
            "\n",
            "    accuracy                           0.52     56709\n",
            "   macro avg       0.52      0.54      0.45     56709\n",
            "weighted avg       0.77      0.52      0.59     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cool_token = '!'\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "outputId": "99b56625-50eb-44b7-dd35-5b4688b08b6f",
        "scrolled": false,
        "id": "-i3bwNacNKGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.48      0.54      0.51     24806\n",
            "    positive       0.61      0.54      0.57     31903\n",
            "\n",
            "    accuracy                           0.54     56709\n",
            "   macro avg       0.54      0.54      0.54     56709\n",
            "weighted avg       0.55      0.54      0.55     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cool_token = ':'\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "outputId": "c90ad6da-43d6-4706-ed44-63187167f39a",
        "id": "f6cJixAwNKGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.85      0.92     32956\n",
            "    positive       0.83      1.00      0.91     23753\n",
            "\n",
            "    accuracy                           0.91     56709\n",
            "   macro avg       0.91      0.93      0.91     56709\n",
            "weighted avg       0.93      0.91      0.91     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cool_token = ')'\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cool_token = '('\n",
        "pred = ['negative' if cool_token in tweet else 'positive' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMlEg0keXCd8",
        "outputId": "8cf0ca42-1fb8-4636-ce29-142249f7b3f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.95      1.00      0.97     26643\n",
            "    positive       1.00      0.95      0.98     30066\n",
            "\n",
            "    accuracy                           0.98     56709\n",
            "   macro avg       0.98      0.98      0.98     56709\n",
            "weighted avg       0.98      0.98      0.98     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза:"
      ],
      "metadata": {
        "id": "RMlLp_CxW8_N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dzZ1WVWNKGu"
      },
      "source": [
        "\")\" Это часть смайлика или сам смайлик - и его присутствие в твите в основном говорит о положительном твите и наоборот.  \n",
        "В свою очередь \"(\" это часть огорченного смайлика - и его присутствие - признак отризательного твита"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q5My_heNKGw"
      },
      "source": [
        "### Задание 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "pV3wzOtSXyls"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "K4mUYtRfNKGw",
        "outputId": "5d91bc10-ad17-407c-e597-2c98dfff7593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.76      0.76     28429\n",
            "    positive       0.76      0.77      0.76     28280\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n",
            "CPU times: user 13.7 s, sys: 9.35 s, total: 23 s\n",
            "Wall time: 17.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "bow = count_vect.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "\n",
        "pred = clf.predict(count_vect.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "scrolled": true,
        "id": "bPSZRss4NKGx",
        "outputId": "c2f0de19-36d4-47ad-b727-37e3b6591b1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.74      0.77      0.75     26994\n",
            "    positive       0.78      0.75      0.77     29715\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n",
            "CPU times: user 15.2 s, sys: 9.87 s, total: 25.1 s\n",
            "Wall time: 17.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "bow = tfidf_vect.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "\n",
        "pred = clf.predict(tfidf_vect.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Rq1XFV6RNKGx"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "scrolled": false,
        "id": "wtD_AU3gNKGx",
        "outputId": "e16733e1-a7d8-4dc4-acad-5f735921fabd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина hash-вектора: 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.58      0.59      0.58     27159\n",
            "    positive       0.62      0.60      0.61     29550\n",
            "\n",
            "    accuracy                           0.60     56709\n",
            "   macro avg       0.60      0.60      0.60     56709\n",
            "weighted avg       0.60      0.60      0.60     56709\n",
            "\n",
            "Длина hash-вектора: 1000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.63      0.65      0.64     27348\n",
            "    positive       0.67      0.65      0.66     29361\n",
            "\n",
            "    accuracy                           0.65     56709\n",
            "   macro avg       0.65      0.65      0.65     56709\n",
            "weighted avg       0.65      0.65      0.65     56709\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина hash-вектора: 10000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.71      0.71     27416\n",
            "    positive       0.73      0.71      0.72     29293\n",
            "\n",
            "    accuracy                           0.71     56709\n",
            "   macro avg       0.71      0.71      0.71     56709\n",
            "weighted avg       0.71      0.71      0.71     56709\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина hash-вектора: 100000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.72      0.75      0.74     27116\n",
            "    positive       0.76      0.74      0.75     29593\n",
            "\n",
            "    accuracy                           0.74     56709\n",
            "   macro avg       0.74      0.74      0.74     56709\n",
            "weighted avg       0.74      0.74      0.74     56709\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина hash-вектора: 1000000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.76      0.74     26942\n",
            "    positive       0.77      0.74      0.76     29767\n",
            "\n",
            "    accuracy                           0.75     56709\n",
            "   macro avg       0.75      0.75      0.75     56709\n",
            "weighted avg       0.75      0.75      0.75     56709\n",
            "\n",
            "CPU times: user 54.9 s, sys: 28.3 s, total: 1min 23s\n",
            "Wall time: 58.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "feature_sizes = [100, 1000, 10000, 100000, 1000000]\n",
        "\n",
        "for feature_size in feature_sizes:\n",
        "    \n",
        "    h_vect = HashingVectorizer(n_features=feature_size)\n",
        "    h_vect.fit(x_train)\n",
        "\n",
        "    xtrain_count =  h_vect.transform(x_train)\n",
        "    xtest_count =  h_vect.transform(x_test)\n",
        "\n",
        "    classifier = LogisticRegression()\n",
        "    classifier.fit(xtrain_count, y_train)\n",
        "    predictions = classifier.predict(xtest_count)\n",
        "    #predictions\n",
        "    print(f'Длина hash-вектора: {feature_size}')\n",
        "    print(classification_report(predictions, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vYv6G3nSNKGy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv1D, GRU, LSTM, Dropout\n",
        "from tensorflow.keras.layers import TextVectorization # формирует словарь как CountVect и TF-IDF \n",
        "# из унгикальных токенов и заменяет кажддый токен его айдишником \n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "AXF9fCuXNKGy"
      },
      "outputs": [],
      "source": [
        "# Приведем y к 0,1\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7h5C23wRNKGz"
      },
      "outputs": [],
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Mwvyl_2uNKGz"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.batch(16)\n",
        "valid_data = valid_data.batch(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wqe_nddMNKG0"
      },
      "outputs": [],
      "source": [
        "for raw in train_data.take(1):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "scrolled": true,
        "id": "qJLOSis9NKG0",
        "outputId": "897e4fc5-70f8-45b5-c6be-80a603c910d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(16,), dtype=string, numpy=\n",
              " array([b'RT @KressVika: \\xd0\\x9f\\xd0\\xb0\\xd1\\x80\\xd0\\xbd\\xd0\\xb8 \\xd0\\xb8\\xd0\\xb7 \\xd1\\x84\\xd0\\xb8\\xd0\\xb7-\\xd0\\xbc\\xd0\\xb0\\xd1\\x82\\xd0\\xb0 \\xd0\\xbb\\xd1\\x83\\xd1\\x87\\xd1\\x88\\xd0\\xb8\\xd0\\xb5, \\xd1\\x83\\xd1\\x80\\xd0\\xbe\\xd0\\xba \\xd0\\xbd\\xd0\\xb0 \\xd1\\x83\\xd1\\x80\\xd0\\xb0)',\n",
              "        b'RT @Abyssal_Blade: @alessen_sun \\n\\xd0\\xba\\xd0\\xb0\\xd0\\xba \\xd0\\xb6\\xd0\\xb5 \\xd1\\x82\\xd1\\x8b \\xd0\\xb1\\xd0\\xb5\\xd0\\xb7 \\xd0\\xba\\xd0\\xb0\\xd1\\x80\\xd0\\xbc\\xd0\\xb0\\xd0\\xbd\\xd0\\xbd\\xd0\\xbe\\xd0\\xb3\\xd0\\xbe \\xd1\\x88\\xd1\\x83\\xd1\\x82\\xd0\\xb0?(',\n",
              "        b'\\xd0\\x94\\xd0\\xbe \\xd1\\x81\\xd0\\xbb\\xd1\\x91\\xd0\\xb7 \\xd0\\xb1\\xd0\\xbb\\xd0\\xb8\\xd0\\xbd \\xd0\\xb7\\xd0\\xb0\\xd0\\xbf\\xd0\\xb8\\xd1\\x81\\xd1\\x8c \\xd0\\xb4\\xd0\\xbe\\xd0\\xb2\\xd0\\xb5\\xd0\\xbb\\xd0\\xb0 ,\\xd0\\xb0\\xd1\\x85\\xd0\\xb0\\xd1\\x85\\xd0\\xb0\\xd1\\x85)))\\n4 \\xd1\\x80\\xd0\\xb0\\xd0\\xb7\\xd0\\xb0 \\xd0\\xbf\\xd0\\xbb\\xd0\\xb0\\xd0\\xba\\xd0\\xb0\\xd0\\xbb\\xd0\\xb0 =))) http://t.co/p259gl1f2s',\n",
              "        b'RT @nebo_oben: @pg__lost \\xd0\\xbd\\xd0\\xb5\\xd1\\x82, \\xd1\\x8d\\xd1\\x82\\xd0\\xbe \\xd0\\xb4\\xd0\\xb0\\xd1\\x88\\xd0\\xb0 \\xd0\\xb8\\xd0\\xb7 \\xd0\\xb0\\xd1\\x80\\xd1\\x85\\xd0\\xb0\\xd0\\xbd\\xd0\\xb3\\xd0\\xb5\\xd0\\xbb\\xd1\\x8c\\xd1\\x81\\xd0\\xba\\xd0\\xb0',\n",
              "        b'@Tina2000Kristi \\xd1\\x8f \\xd0\\xb4\\xd0\\xb0\\xd0\\xb6\\xd0\\xb5 \\xd0\\xbd\\xd0\\xb5 \\xd1\\x85\\xd0\\xbe\\xd1\\x87\\xd1\\x83 \\xd0\\xb3\\xd0\\xbe\\xd0\\xb2\\xd0\\xbe\\xd1\\x80\\xd0\\xb8\\xd1\\x82\\xd1\\x8c \\xd0\\xbd\\xd0\\xb0 \\xd1\\x8d\\xd1\\x82\\xd1\\x83 \\xd1\\x82\\xd0\\xb5\\xd0\\xbc\\xd1\\x83.\\xd0\\x9f\\xd0\\xbe\\xd1\\x82\\xd0\\xbe\\xd0\\xbc\\xd1\\x83 \\xd1\\x87\\xd1\\x82\\xd0\\xbe \\xd0\\xbc\\xd0\\xbd\\xd0\\xb5 \\xd1\\x81\\xd1\\x82\\xd1\\x8b\\xd0\\xb4\\xd0\\xbd\\xd0\\xbe \\xd0\\xb7\\xd0\\xb0 \\xd0\\xbd\\xd0\\xb0\\xd1\\x88\\xd1\\x83 \\xd0\\xa3\\xd0\\xba\\xd1\\x80\\xd0\\xb0\\xd0\\xb8\\xd0\\xbd\\xd1\\x83;(',\n",
              "        b'\\xd0\\xa2\\xd1\\x80\\xd0\\xb0\\xd0\\xbc\\xd0\\xb2\\xd0\\xb0\\xd0\\xb9\\xd1\\x87\\xd0\\xb8\\xd0\\xba \\xd0\\xba\\xd0\\xb0\\xd1\\x82\\xd0\\xb0\\xd0\\xb5\\xd0\\xbc, \\xd0\\xbd\\xd0\\xb0 \\xd1\\x8d\\xd1\\x82\\xd0\\xbe\\xd1\\x82 \\xd1\\x80\\xd0\\xb0\\xd0\\xb7 \\xd0\\xbc\\xd0\\xb5\\xd0\\xbd\\xd1\\x8f \\xd0\\xbd\\xd0\\xb5 \\xd0\\xbf\\xd1\\x83\\xd1\\x81\\xd1\\x82\\xd0\\xb8\\xd0\\xbb\\xd0\\xb8 :-( \\xd1\\x81\\xd0\\xba\\xd0\\xb0\\xd0\\xb7\\xd0\\xb0\\xd0\\xbb\\xd0\\xb8 \\xd0\\xb4\\xd1\\x80\\xd1\\x83\\xd0\\xb3\\xd0\\xb8\\xd0\\xbc \\xd0\\xba\\xd0\\xb0\\xd1\\x82\\xd0\\xb0\\xd1\\x82\\xd1\\x8c\\xd1\\x81\\xd1\\x8f, \\xd0\\xb0 \\xd1\\x8f \\xd0\\xbf\\xd0\\xbe\\xd1\\x82\\xd0\\xbe\\xd0\\xbc \\xd0\\xb5\\xd1\\x89\\xd0\\xb5 \\xd0\\xbd\\xd0\\xb0 \\xd0\\xba\\xd0\\xb0\\xd1\\x82\\xd0\\xb0\\xd1\\x8e\\xd1\\x81\\xd1\\x8c...',\n",
              "        b'\\xd0\\x9f\\xd0\\xb5\\xd1\\x80\\xd0\\xb5\\xd0\\xbc\\xd0\\xb5\\xd1\\x80\\xd0\\xb8\\xd0\\xbb\\xd0\\xb0 \\xd1\\x86\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xba\\xd0\\xb0\\xd1\\x84 \\xd0\\xbe\\xd0\\xb4\\xd0\\xb5\\xd0\\xb6\\xd0\\xb4\\xd1\\x8b....\\xd0\\xbc\\xd0\\xbd\\xd0\\xb5 \\xd1\\x83\\xd0\\xbf\\xd0\\xbe\\xd1\\x80\\xd0\\xbd\\xd0\\xbe \\xd0\\xbd\\xd0\\xb5 \\xd0\\xb8\\xd0\\xb4\\xd1\\x83\\xd1\\x82 \\xd1\\x8d\\xd1\\x82\\xd0\\xb8 \\xd1\\x82\\xd1\\x80\\xd1\\x8f\\xd0\\xbf\\xd1\\x83\\xd1\\x81\\xd1\\x8c\\xd0\\xba\\xd0\\xb8 =( ..... \\xd0\\xb1\\xd0\\xb5\\xd0\\xb7 \\xd0\\xbd\\xd0\\xb8\\xd1\\x85, \\xd0\\xbd\\xd0\\xb0\\xd0\\xbc\\xd0\\xbd\\xd0\\xbe\\xd0\\xb3\\xd0\\xbe \\xd0\\xbb\\xd1\\x83\\xd1\\x87\\xd1\\x88\\xd0\\xb5 ... \\xd1\\x85DDD\\xc2\\xa0',\n",
              "        b'@alina___styles \\xd1\\x82\\xd0\\xb0\\xd0\\xba... \\xd0\\x93\\xd0\\x9f, \\xd0\\xa7\\xd0\\xb0\\xd0\\xba\\xd0\\xb0 \\xd0\\x9f\\xd0\\xb0\\xd0\\xbb\\xd0\\xb0\\xd0\\xbd\\xd0\\xb8\\xd0\\xba\\xd0\\xb0, \\xd0\\x90\\xd0\\xbd\\xd0\\xb8\\xd0\\xbc\\xd0\\xb5 \\xd0\\xbd\\xd0\\xb5\\xd0\\xba\\xd0\\xbe\\xd1\\x82\\xd0\\xbe\\xd1\\x80\\xd1\\x8b\\xd0\\xb5,\\xd0\\xa5\\xd0\\xb5\\xd0\\xbb\\xd0\\xb5\\xd0\\xbd\\xd1\\x83, \\xd0\\x94\\xd0\\xb5\\xd0\\xbf\\xd0\\xbf\\xd0\\xb0, \\xd0\\xa1\\xd0\\x9f\\xd0\\x90\\xd0\\xa2\\xd0\\xac, \\xd0\\x95\\xd0\\xa1\\xd0\\xa2\\xd0\\xac \\xd1\\x85\\xd0\\xb0\\xd1\\x85 ...\\xd0\\x9a\\xd0\\xbb\\xd0\\xb8\\xd0\\xbd\\xd0\\xb8\\xd0\\xba\\xd0\\xb0, \\xd0\\xa5\\xd0\\xb0\\xd1\\x83\\xd1\\x81 \\xd0\\xb8 \\xd1\\x82\\xd0\\xb4 )',\n",
              "        b'\\xd0\\xb7\\xd0\\xb0\\xd1\\x87\\xd0\\xb5\\xd0\\xbc \\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd1\\x88\\xd0\\xbb\\xd0\\xb0 \\xd0\\xb2 \\xd0\\xb8\\xd0\\xbd\\xd1\\x82\\xd0\\xb5\\xd1\\x80\\xd0\\xbd\\xd0\\xb5\\xd1\\x82?((( \\xd0\\xbf\\xd0\\xbe\\xd1\\x87\\xd0\\xb8\\xd1\\x82\\xd0\\xb0\\xd0\\xbb\\xd0\\xb0 \\xd0\\xb4\\xd0\\xb8\\xd0\\xb0\\xd0\\xb3\\xd0\\xbd\\xd0\\xbe\\xd0\\xb7 \\xd0\\xb8 \\xd0\\xbc\\xd0\\xbd\\xd0\\xb5 \\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd0\\xbb\\xd0\\xbe \\xd1\\x81\\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd1\\x88\\xd0\\xbd\\xd0\\xbe( \\xd0\\xbf\\xd0\\xb8\\xd0\\xbf\\xd0\\xb5\\xd1\\x86 \\xd0\\xba\\xd0\\xb0\\xd0\\xba \\xd1\\x81\\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd1\\x88\\xd0\\xbd\\xd0\\xbe(',\n",
              "        b'@OlyaValsbaston @Yaroslaw_spb )) \\xd0\\xb8 \\xd1\\x81 \\xd0\\xb3\\xd0\\xb2\\xd0\\xbe\\xd0\\xb7\\xd0\\xb4\\xd0\\xb8\\xd0\\xba\\xd0\\xbe\\xd0\\xb9... \\xd0\\xb8 \\xd1\\x81 \\xd0\\xba\\xd0\\xb0\\xd1\\x80\\xd0\\xb4\\xd0\\xb0\\xd0\\xbc\\xd0\\xbe\\xd0\\xbd\\xd0\\xbe\\xd0\\xbc... ))',\n",
              "        b'\\xd0\\x93\\xd0\\xbe\\xd0\\xbd\\xd1\\x8f\\xd0\\xbb\\xd0\\xb8 \\xd1\\x81 \\xd0\\xa0\\xd0\\xbe\\xd0\\xbc\\xd0\\xb0\\xd1\\x88\\xd0\\xba\\xd0\\xbe\\xd0\\xb9 \\xd0\\xb2 \\xd0\\xbc\\xd0\\xb0\\xd0\\xb3\\xd0\\xb0\\xd0\\xb7\\xd0\\xb8\\xd0\\xbd \\xd0\\xb7\\xd0\\xb0 \\xd1\\x81\\xd0\\xbb\\xd0\\xb0\\xd0\\xb4\\xd0\\xba\\xd0\\xbe\\xd0\\xb9 \\xd0\\xb2\\xd0\\xb0\\xd1\\x82\\xd0\\xbe\\xd0\\xb9*-* \\xd0\\x9d\\xd0\\xbe \\xd0\\xb5\\xd1\\x91 \\xd0\\xbd\\xd0\\xb5 \\xd0\\xbe\\xd0\\xba\\xd0\\xb0\\xd0\\xb7\\xd0\\xb0\\xd0\\xbb\\xd0\\xbe\\xd1\\x81\\xd1\\x8c(( \\xd0\\x97\\xd0\\xb0\\xd1\\x82\\xd0\\xbe \\xd0\\xb1\\xd1\\x8b\\xd0\\xbb\\xd0\\xb8 \\xd0\\xbc\\xd0\\xbe\\xd1\\x8e \\xd0\\xbb\\xd1\\x8e\\xd0\\xb1\\xd0\\xb8\\xd0\\xbc\\xd1\\x8b\\xd0\\xb5 \"3 \\xd0\\xba\\xd0\\xbe\\xd1\\x80\\xd0\\xbe\\xd1\\x87\\xd0\\xba\\xd0\\xb8\" \\xe3\\x8b\\x9b \\n\\xd0\\x97\\xd0\\xb0 \\xd0\\xb2\\xd0\\xb0\\xd1\\x82\\xd0\\xbe\\xd0\\xb9 \\xd1\\x80\\xd0\\xbe\\xd0\\xb4\\xd0\\xbd\\xd0\\xbe\\xd0\\xb9 \\xd1\\x81\\xd0\\xba\\xd0\\xb0\\xd0\\xb7\\xd0\\xb0\\xd0\\xbb \\xd0\\xbe\\xd1\\x82\\xd0\\xb2\\xd0\\xb5\\xd0\\xb7\\xd1\\x91\\xd1\\x82 \\xd0\\xb2..',\n",
              "        b'RT @ifuckatyajones: @NotBulletproof_ \\xd0\\xb1\\xd0\\xb5\\xd1\\x81\\xd1\\x81\\xd0\\xbf\\xd0\\xbe\\xd1\\x80\\xd0\\xbd\\xd0\\xbe \\xd0\\xbd\\xd0\\xb5\\xd0\\xbb\\xd1\\x8c\\xd0\\xb7\\xd1\\x8f \\xd0\\xb1\\xd0\\xb5\\xd0\\xb7 \\xd0\\xbf\\xd0\\xbe\\xd1\\x80\\xd0\\xbd\\xd0\\xbe :D',\n",
              "        b'@vse_ahuenno_ \\xd0\\xb8\\xd0\\xbd\\xd1\\x82\\xd0\\xb5\\xd1\\x80\\xd0\\xb5\\xd1\\x81\\xd0\\xbd\\xd0\\xb0 \\xd1\\x82\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c\\xd0\\xba\\xd0\\xbe \\xd0\\xbf\\xd0\\xb5\\xd1\\x80\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd1\\x87\\xd0\\xb0\\xd1\\x81\\xd1\\x82\\xd1\\x8c. \\xd0\\xad\\xd1\\x82\\xd0\\xbe \\xd1\\x82\\xd0\\xbe\\xd1\\x87\\xd0\\xbd\\xd0\\xbe. \\xd0\\x98\\xd1\\x81\\xd0\\xbf\\xd0\\xbe\\xd1\\x80\\xd1\\x82\\xd0\\xb8\\xd1\\x82 \\xd1\\x82\\xd0\\xb0\\xd0\\xba\\xd0\\xbe\\xd0\\xb3\\xd0\\xbe \\xd0\\xbf\\xd0\\xb0\\xd1\\x80\\xd0\\xbd\\xd1\\x8f:(',\n",
              "        b'\\xd0\\xb2\\xd1\\x87\\xd0\\xb5\\xd1\\x80\\xd0\\xb0 \\xd1\\x83\\xd0\\xb2\\xd0\\xb8\\xd0\\xb4\\xd0\\xb5\\xd0\\xbb\\xd0\\xb0 \\xd0\\xba\\xd0\\xb0\\xd0\\xba \\xd0\\xbe\\xd0\\xbd \\xd0\\xbe\\xd0\\xb1\\xd0\\xbd\\xd1\\x8f\\xd0\\xbb \\xd0\\xb8 \\xd0\\xbf\\xd0\\xbe\\xd1\\x87\\xd0\\xb5\\xd0\\xbb\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd0\\xbb \\xd0\\xb4\\xd1\\x80\\xd1\\x83\\xd0\\xb3\\xd1\\x83\\xd1\\x8e...\\xd1\\x8f \\xd0\\xbd\\xd0\\xb5 \\xd0\\xb4\\xd1\\x83\\xd0\\xbc\\xd0\\xb0\\xd0\\xbb\\xd0\\xb0 \\xd1\\x87\\xd1\\x82\\xd0\\xbe \\xd1\\x8d\\xd1\\x82\\xd0\\xbe \\xd0\\xbd\\xd0\\xb0 \\xd1\\x81\\xd1\\x82\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c\\xd0\\xba\\xd0\\xbe \\xd0\\xb1\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c\\xd0\\xbd\\xd0\\xbe...\\xd0\\xbd\\xd0\\xb5 \\xd0\\xb4\\xd1\\x83\\xd0\\xbc\\xd0\\xb0\\xd0\\xbb\\xd0\\xb0 \\xd1\\x87\\xd1\\x82\\xd0\\xbe \\xd0\\xbd\\xd0\\xb5 \\xd1\\x81\\xd0\\xbc\\xd0\\xbe\\xd0\\xb3\\xd1\\x83 \\xd1\\x87\\xd0\\xb4\\xd0\\xb5\\xd1\\x80\\xd0\\xb6\\xd0\\xb0\\xd1\\x82\\xd1\\x8c \\xd1\\x81\\xd0\\xbb\\xd0\\xb5\\xd0\\xb7\\xd1\\x8b..((',\n",
              "        b'@bikyshaa \\xd0\\xb5\\xd1\\x81\\xd0\\xbb\\xd0\\xb8 \\xd0\\xb2\\xd0\\xbe 2 \\xd1\\x81\\xd0\\xb5\\xd0\\xbc\\xd0\\xb5\\xd1\\x81\\xd1\\x82\\xd1\\x80\\xd0\\xb5 \\xd1\\x82\\xd0\\xb0\\xd0\\xba \\xd0\\xb1\\xd1\\x83\\xd0\\xb4\\xd0\\xb5\\xd1\\x82,\\xd1\\x8f \\xd0\\xb1\\xd0\\xbb\\xd0\\xb8\\xd0\\xbd \\xd1\\x82\\xd0\\xbe\\xd0\\xb6\\xd0\\xb5 \\xd0\\xb1\\xd1\\x83\\xd0\\xb4\\xd1\\x83 \\xd1\\x83\\xd1\\x87\\xd0\\xb0\\xd1\\x81\\xd1\\x82\\xd0\\xb2\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x82\\xd1\\x8c)',\n",
              "        b'\\xd0\\xb4\\xd0\\xbe\\xd0\\xb1\\xd1\\x80\\xd0\\xbe\\xd0\\xb5 \\xd1\\x83\\xd1\\x82\\xd1\\x80\\xd0\\xbe,\\xd1\\x85\\xd0\\xbe\\xd1\\x80\\xd0\\xbe\\xd1\\x88\\xd0\\xb5\\xd0\\xb3\\xd0\\xbe \\xd0\\xb4\\xd0\\xbd\\xd1\\x8f\\n\\xd0\\xb8 \\xd0\\xbc\\xd0\\xb0\\xd0\\xbb\\xd1\\x8b\\xd1\\x88\\xd0\\xba\\xd0\\xb0\\xd0\\xbc \\xd0\\xbc\\xd0\\xbe\\xd0\\xb8\\xd0\\xbc \\xd1\\x85\\xd0\\xbe\\xd1\\x80\\xd0\\xbe\\xd1\\x88\\xd0\\xb5\\xd0\\xb9 \\xd0\\xb8\\xd0\\xb3\\xd1\\x80\\xd1\\x8b:*'],\n",
              "       dtype=object)>,\n",
              " <tf.Tensor: shape=(16,), dtype=int64, numpy=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1])>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5P2oqangNKG0"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_data):\n",
        "    \n",
        "    return input_data\n",
        "\n",
        "vocab_size = 10000 # выбрали 10000 а там было 31к\n",
        "seq_len = 100 # сколько токенов в тексте -проходят по всем текстам и выбирают максимум, или берут квантильное - \n",
        "# могут быть выбросы по длинам \n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int', # что каждый токен будем переводить в индекс относительно нашего словаря vocab_size\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)\n",
        "\n",
        "embedding_dim=200 # 200-мерные вектора будут у каждого токена"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "r_uP94MsNKG1"
      },
      "outputs": [],
      "source": [
        "class myNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(myNet, self).__init__()\n",
        "        self.emb = Embedding(vocab_size, embedding_dim, name=\"embedding\")\n",
        "        self.conv1 = Conv1D(200, (3))\n",
        "        self.conv2 = Conv1D(200, (3))\n",
        "        self.gPool = GlobalAveragePooling1D()\n",
        "        self.fc1 = Dense(100, activation='relu')\n",
        "        self.fc2 = Dense(1)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        x = vectorize_layer(x)\n",
        "        x = self.emb(x)\n",
        "        x1 = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.gPool((x + x1)/2)\n",
        "        x = self.fc1(x)\n",
        "#         x = self.ss(x)\n",
        "        return self.fc2(x)\n",
        "    \n",
        "# тут подход что все выделено в класс - ти удобнее писать в таком подходе!!!!\n",
        "# так как еслп будут повторться слои "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1E2y1CQANKG1"
      },
      "outputs": [],
      "source": [
        "mmodel = myNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "akwGfKCdNKG2"
      },
      "outputs": [],
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RkVBXO4LNKG2",
        "outputId": "f441339a-b0ee-4886-b7ad-cb71a2b2f721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10633/10633 [==============================] - 98s 8ms/step - loss: 0.3893 - accuracy: 0.7753 - val_loss: 0.3479 - val_accuracy: 0.7951\n",
            "Epoch 2/5\n",
            "10633/10633 [==============================] - 70s 7ms/step - loss: 0.3276 - accuracy: 0.8189 - val_loss: 0.3403 - val_accuracy: 0.8100\n",
            "Epoch 3/5\n",
            "10633/10633 [==============================] - 69s 6ms/step - loss: 0.3053 - accuracy: 0.8335 - val_loss: 0.3450 - val_accuracy: 0.8057\n",
            "Epoch 4/5\n",
            "10633/10633 [==============================] - 68s 6ms/step - loss: 0.2848 - accuracy: 0.8469 - val_loss: 0.3736 - val_accuracy: 0.7972\n",
            "Epoch 5/5\n",
            "10633/10633 [==============================] - 68s 6ms/step - loss: 0.2617 - accuracy: 0.8618 - val_loss: 0.4066 - val_accuracy: 0.8129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75a8a4d640>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcW6_aWVNKG3"
      },
      "source": [
        "Переобучение уже пошло с 3-й эпохи - и дальше стало только усиливаться"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "THENgUwMNKG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14ed99a-24fb-4bb5-8406-2596d59a5735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3545/3545 [==============================] - 7s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = mmodel.predict(valid_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": true,
        "id": "xT-M0nNANKG3",
        "outputId": "56e07534-9089-4664-ff64-016e88e7a62e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 22.623535 ],\n",
              "       [ -0.5340227],\n",
              "       [ 18.50459  ],\n",
              "       ...,\n",
              "       [  0.4341001],\n",
              "       [ -7.740841 ],\n",
              "       [-28.200327 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "I682BO3PNKG4"
      },
      "outputs": [],
      "source": [
        "# Приведем preds в бинарный вид\n",
        "preds = [int(i[0]>0) for i in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JHEr4BLXNKG4",
        "outputId": "0b1a0b6d-2471-4bff-a68d-06b5b2ad8a60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82     27191\n",
            "           1       0.84      0.81      0.82     29518\n",
            "\n",
            "    accuracy                           0.82     56709\n",
            "   macro avg       0.82      0.82      0.82     56709\n",
            "weighted avg       0.82      0.82      0.82     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# pred = clf.predict(tfidf_vect.transform(x_test))\n",
        "print(classification_report(preds, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "L4HQ1xJENKG5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}